{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c97a98e9",
   "metadata": {},
   "source": [
    "From https://machinelearninggeek.com/text-analytics-for-beginner-using-textblob/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd4ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b5e27",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "Tokenization is the process of splitting text documents into small pieces, known as tokens. It will ignore punctuations and spaces from the text document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89b34071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'want', 'to', 'be', 'remembered', 'not', 'only', 'as', 'an', 'entertainer', 'but', 'as', 'a', 'person', 'who', 'cared', 'a', 'lot', 'and', 'I', 'gave', 'the', 'best', 'that', 'I', 'could', 'I', 'tried', 'to', 'be', 'the', 'best', 'role', 'model', 'that', 'I', 'possibly', 'could']\n"
     ]
    }
   ],
   "source": [
    "# Create TextBlob object\n",
    "text = TextBlob(\"I want to be remembered not only as an entertainer but as a person who cared a lot, and I gave the best that I could. I tried to be the best role model that I possibly could.\")\n",
    "\n",
    "# Print the tokens\n",
    "print(text.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1990224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"I want to be remembered not only as an entertainer but as a person who cared a lot, and I gave the best that I could.\"), Sentence(\"I tried to be the best role model that I possibly could.\")]\n"
     ]
    }
   ],
   "source": [
    "# Print the tokenized sentences\n",
    "print(text.sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd0c7f",
   "metadata": {},
   "source": [
    "# Noun Phrases\n",
    "A noun phrase is a set of words that belongs to a noun. It can be a subject or object in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e00f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['role model']\n"
     ]
    }
   ],
   "source": [
    "# Print noun phrases\n",
    "print(text.noun_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49357185",
   "metadata": {},
   "source": [
    "# Part of Speech (POS) Tagging\n",
    "\n",
    "Part of speech or PoS defines the function of any sentence. For example, the verb identifies the action, noun or adjective identifies the object. Discovering such labels into the data is called PoS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e140a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('be', 'VB'), ('remembered', 'VBN'), ('not', 'RB'), ('only', 'RB'), ('as', 'IN'), ('an', 'DT'), ('entertainer', 'NN'), ('but', 'CC'), ('as', 'IN'), ('a', 'DT'), ('person', 'NN'), ('who', 'WP'), ('cared', 'VBD'), ('a', 'DT'), ('lot', 'NN'), ('and', 'CC'), ('I', 'PRP'), ('gave', 'VBD'), ('the', 'DT'), ('best', 'JJS'), ('that', 'IN'), ('I', 'PRP'), ('could', 'MD'), ('I', 'PRP'), ('tried', 'VBD'), ('to', 'TO'), ('be', 'VB'), ('the', 'DT'), ('best', 'JJS'), ('role', 'NN'), ('model', 'NN'), ('that', 'IN'), ('I', 'PRP'), ('possibly', 'RB'), ('could', 'MD')]\n"
     ]
    }
   ],
   "source": [
    "#Print PoS tags\n",
    "print(text.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a57c91",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "\n",
    "Lemmatization is a process of normalizing the text in a linguistic manner. It chops the given input text and provides the root word of a given word with the use of a vocabulary and morphological analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a20e3cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "care\n"
     ]
    }
   ],
   "source": [
    "print(text.words[15].lemmatize(\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01617086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remember\n"
     ]
    }
   ],
   "source": [
    "# Import word\n",
    "from textblob import Word\n",
    "\n",
    "# Create Word object\n",
    "w = Word(\"remembered\")\n",
    "\n",
    "# Print lemmatized word\n",
    "print(w.lemmatize(\"v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448cfd28",
   "metadata": {},
   "source": [
    "# Finding a word and counting its occurrence\n",
    "\n",
    "TextBlob has a find() function for searching the word and a count() function for counting the occurrence of any word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aa5e134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find a string\n",
    "text.find(\"care\") # returns the start index of that string in original text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e468198",
   "metadata": {},
   "source": [
    "# n-grams\n",
    "n-grams or bag of word model is used to find the frequency of words in a given text document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f000a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Count number of times I appeared\n",
    "print(text.words.count('I'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59990a3",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "In TextBlob, sentiment property returns two scores(polarity, subjectivity) in namedtuple. The polarity score lies between -1 to +1. Negative values show negative sentiment or opinion while positive values show positive opinion or sentiment. The Subjectivity range between 0 and 1. Here, zero means objective and 1 means subjective opinion.\n",
    "\n",
    "TextBlob offers two implementations of sentiment analysis. One is based on a pattern library and the other is based on an NLTK classifier trained on a movie reviews corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18789272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.5, subjectivity=0.65)\n"
     ]
    }
   ],
   "source": [
    "# Print the polarity and subjectivity\n",
    "print(text.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4fe694",
   "metadata": {},
   "source": [
    "# Spell Correction\n",
    "TextBlob offers spell correction using the correct() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ceced65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have good spelling!\n"
     ]
    }
   ],
   "source": [
    "# Create TextBlob object\n",
    "b = TextBlob(\"I havv goood speling!\")\n",
    "print(b.correct())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be456dc4",
   "metadata": {},
   "source": [
    "# Language Detection and Translation\n",
    "TextBlob offers detect_language() function for detection languages and translate() for translate text from one language to another language. It uses Google Translate API. To run these functions, requires an internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5610bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "# # Create TextBlob object\n",
    "# text = TextBlob(\"नमस्ते आप कैसे हैं\")\n",
    "\n",
    "# # Detect Language\n",
    "# print(text.detect_language())\n",
    "\n",
    "# # Translate into english\n",
    "# print(text.translate(to='en'))\n",
    "\n",
    "## This is broken and it's just too much trouble to fix it. \n",
    "## It's better to use other libraries for translation, example deep_translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba7a887",
   "metadata": {},
   "source": [
    "# Text Classification using TextBlob\n",
    "In this section, we will focus on text classification which is one of the most important NLP techniques. Text classification will help us in various applications such as document classification, sentiment classification, predicting review rating, spam filtering, support tickets classification, and fake news classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed206d",
   "metadata": {},
   "source": [
    "# Prepare Dataset\n",
    "In this section, our main objective is to prepare a dataset. Let’s prepare data by writing sentences and their sentiment in a tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb714cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\n",
    "...     ('I love this sandwich.', 'pos'),\n",
    "...     ('this is an amazing place!', 'pos'),\n",
    "...     ('I feel very good about these beers.', 'pos'),\n",
    "...     ('this is my best work.', 'pos'),\n",
    "...     (\"what an awesome view\", 'pos'),\n",
    "...     ('I do not like this restaurant', 'neg'),\n",
    "...     ('I am tired of this stuff.', 'neg'),\n",
    "...     (\"I can't deal with this\", 'neg'),\n",
    "...     ('he is my sworn enemy!', 'neg'),\n",
    "...     ('my boss is horrible.', 'neg')\n",
    "... ]\n",
    "\n",
    "test = [\n",
    "...     ('the beer was good.', 'pos'),\n",
    "...     ('I do not enjoy my job', 'neg'),\n",
    "...     (\"I ain't feeling dandy today.\", 'neg'),\n",
    "...     (\"I feel amazing!\", 'pos'),\n",
    "...     ('Gary is a friend of mine.', 'pos'),\n",
    "...     (\"I can't believe I'm doing this.\", 'neg')\n",
    "... ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37057cda",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "In this section, we are going to create a NaiveBayes classifier using TextBlob. Let’s create a NaiveBayes classifier and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3dfe5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NaiveBayes Classifier\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "# Perofrm model training\n",
    "cl = NaiveBayesClassifier(train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1affc6",
   "metadata": {},
   "source": [
    "# Make Prediction\n",
    "Let’s make prediction on the given input sentence in the below code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fa959a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "print(cl.classify(\"This is an amazing library!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6adfa22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "print(cl.classify(\"Gary is a friend of mine.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5e8aa5",
   "metadata": {},
   "source": [
    "# Evaluate Model\n",
    "Let’s evaluate the model performance using the accuracy method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c4cf5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "cl.accuracy(test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aadae6",
   "metadata": {},
   "source": [
    "In the above code, we have assessed the performance using accuracy measure and we have got 83.33 % accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47eda68",
   "metadata": {},
   "source": [
    "# Retraining Model\n",
    "Let’s retrain the model using the update method. First, we will prepare the new dataset and then update the previously trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c4e2cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare new data\n",
    "new_data = [('She is my best friend.', 'pos'),\n",
    "            (\"I'm happy to have a new friend.\", 'pos'),\n",
    "            (\"Stay thirsty, my friend.\", 'pos'),\n",
    "            (\"He ain't from around here.\", 'neg')]\n",
    "\n",
    "# Update model with new data\n",
    "cl.update(new_data) # 4. retraining of model\n",
    "\n",
    "# Test the model \n",
    "cl.classify(\"Gary is a friend of mine.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28a1cf",
   "metadata": {},
   "source": [
    "# Calculate Class Probabilities\n",
    "We can also calculate the probabilities for predicted classes using the prob_classify(text) function. Let’s see the example below for detailed understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "509bfa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive and Negative Probabilities: 0.9256990307165033 0.07430096928349521\n",
      "Largest Probability: pos\n"
     ]
    }
   ],
   "source": [
    "cl = NaiveBayesClassifier(train)\n",
    "prob_dist = cl.prob_classify(\"I feel happy this morning.\")\n",
    "\n",
    "print(\"Positive and Negative Probabilities:\",prob_dist.prob(\"pos\"),prob_dist.prob(\"neg\"))\n",
    "print(\"Largest Probability:\",prob_dist.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15c9f7e",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "Let’s train the model using the Decision Tree Classifier using TextBlob and evaluate the model performance using the accuracy method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8ea2422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Decision Tree\n",
    "from textblob.classifiers import DecisionTreeClassifier\n",
    "\n",
    "# Create Decision Tree Classifier\n",
    "dt=DecisionTreeClassifier(train)\n",
    "\n",
    "# Test the model\n",
    "dt.accuracy(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f4d120",
   "metadata": {},
   "source": [
    "# Maximum Entropy Classifier\n",
    "Let’s train the model using Maximum Entropy Classifier using TextBlob and evaluate the model performance using the accuracy method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81898cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.571\n",
      "             2          -0.64213        0.571\n",
      "             3          -0.61362        0.571\n",
      "             4          -0.58734        0.643\n",
      "             5          -0.56305        0.857\n",
      "             6          -0.54057        0.857\n",
      "             7          -0.51971        0.857\n",
      "             8          -0.50032        0.929\n",
      "             9          -0.48226        0.929\n",
      "            10          -0.46540        0.929\n",
      "            11          -0.44963        0.929\n",
      "            12          -0.43486        0.929\n",
      "            13          -0.42099        1.000\n",
      "            14          -0.40795        1.000\n",
      "            15          -0.39567        1.000\n",
      "            16          -0.38408        1.000\n",
      "            17          -0.37312        1.000\n",
      "            18          -0.36275        1.000\n",
      "            19          -0.35293        1.000\n",
      "            20          -0.34360        1.000\n",
      "            21          -0.33474        1.000\n",
      "            22          -0.32630        1.000\n",
      "            23          -0.31827        1.000\n",
      "            24          -0.31061        1.000\n",
      "            25          -0.30329        1.000\n",
      "            26          -0.29630        1.000\n",
      "            27          -0.28961        1.000\n",
      "            28          -0.28321        1.000\n",
      "            29          -0.27707        1.000\n",
      "            30          -0.27118        1.000\n",
      "            31          -0.26553        1.000\n",
      "            32          -0.26010        1.000\n",
      "            33          -0.25488        1.000\n",
      "            34          -0.24985        1.000\n",
      "            35          -0.24502        1.000\n",
      "            36          -0.24035        1.000\n",
      "            37          -0.23586        1.000\n",
      "            38          -0.23152        1.000\n",
      "            39          -0.22734        1.000\n",
      "            40          -0.22329        1.000\n",
      "            41          -0.21939        1.000\n",
      "            42          -0.21561        1.000\n",
      "            43          -0.21195        1.000\n",
      "            44          -0.20841        1.000\n",
      "            45          -0.20498        1.000\n",
      "            46          -0.20166        1.000\n",
      "            47          -0.19844        1.000\n",
      "            48          -0.19532        1.000\n",
      "            49          -0.19229        1.000\n",
      "            50          -0.18935        1.000\n",
      "            51          -0.18649        1.000\n",
      "            52          -0.18372        1.000\n",
      "            53          -0.18102        1.000\n",
      "            54          -0.17840        1.000\n",
      "            55          -0.17585        1.000\n",
      "            56          -0.17337        1.000\n",
      "            57          -0.17096        1.000\n",
      "            58          -0.16861        1.000\n",
      "            59          -0.16632        1.000\n",
      "            60          -0.16409        1.000\n",
      "            61          -0.16192        1.000\n",
      "            62          -0.15980        1.000\n",
      "            63          -0.15773        1.000\n",
      "            64          -0.15572        1.000\n",
      "            65          -0.15375        1.000\n",
      "            66          -0.15183        1.000\n",
      "            67          -0.14996        1.000\n",
      "            68          -0.14813        1.000\n",
      "            69          -0.14634        1.000\n",
      "            70          -0.14459        1.000\n",
      "            71          -0.14289        1.000\n",
      "            72          -0.14122        1.000\n",
      "            73          -0.13959        1.000\n",
      "            74          -0.13799        1.000\n",
      "            75          -0.13643        1.000\n",
      "            76          -0.13491        1.000\n",
      "            77          -0.13341        1.000\n",
      "            78          -0.13195        1.000\n",
      "            79          -0.13052        1.000\n",
      "            80          -0.12912        1.000\n",
      "            81          -0.12774        1.000\n",
      "            82          -0.12640        1.000\n",
      "            83          -0.12508        1.000\n",
      "            84          -0.12379        1.000\n",
      "            85          -0.12252        1.000\n",
      "            86          -0.12128        1.000\n",
      "            87          -0.12006        1.000\n",
      "            88          -0.11887        1.000\n",
      "            89          -0.11770        1.000\n",
      "            90          -0.11655        1.000\n",
      "            91          -0.11542        1.000\n",
      "            92          -0.11431        1.000\n",
      "            93          -0.11323        1.000\n",
      "            94          -0.11216        1.000\n",
      "            95          -0.11111        1.000\n",
      "            96          -0.11008        1.000\n",
      "            97          -0.10907        1.000\n",
      "            98          -0.10808        1.000\n",
      "            99          -0.10711        1.000\n",
      "         Final          -0.10615        1.000\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Import MaxEntClassifier\n",
    "from textblob.classifiers import MaxEntClassifier\n",
    "\n",
    "# Create Decision Tree Classifier\n",
    "me = MaxEntClassifier(train)\n",
    "\n",
    "# Test the model\n",
    "print(me.accuracy(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6bd8e2",
   "metadata": {},
   "source": [
    "# Pros and Cons\n",
    "TextBlob is built on top of the NLTK and Pattern library. It provides a simple intuitive interface for beginners. It also offers language detection, language translation (powered by Google Translate), Sentiment analysis, and easy-to-use Text Classification functionality.\n",
    "\n",
    "TextBlob is slower than Spacy but faster than NLTK. It does not offer a few NLP tasks such as word vectorization and dependency parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818c905e",
   "metadata": {},
   "source": [
    "# Summary\n",
    "We have performed various NLP operations such as PoS tagging, noun phrases, sentiment analysis, parsing, spell correction, language detection, language translation, and text classification using Naive Bayes and Decision Tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7ccb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a1d68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08836a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89bc623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e477d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
